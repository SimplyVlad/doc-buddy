{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48ec7cdb",
   "metadata": {},
   "source": [
    "# RAG receiver notebook\n",
    "\n",
    "This notebook servers as the interface for experimental interaction with the RAG application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3eb0a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58d709e",
   "metadata": {},
   "source": [
    "Provide an address to the endpoint - in our case we've used an ngrock funnel to access the hosted models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ecd70d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_link = os.getenv('NG_LINK', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "674a24dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_post_completion = ng_link + \"/v1/completions\"\n",
    "request_post_search = ng_link + \"/v1/search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6616c767",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9de9f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_results(question):\n",
    "    \"\"\"\n",
    "    Retrieves search results for a given question using a POST request.\n",
    "\n",
    "    Args:\n",
    "        question (str): The question to search for.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the context and context UID retrieved from the search results.\n",
    "    \"\"\"\n",
    "    payload = {\"query\": question}\n",
    "    result = requests.post(request_post_search, json=payload, stream=False)\n",
    "    result_str = json.loads(result.content)\n",
    "    results = result_str[\"result\"]\n",
    "    context = results.get(\"context\", \"\")\n",
    "    context_uid = results.get(\"context_uid\", \"\")\n",
    "    return context, context_uid\n",
    "\n",
    "def generate_model_response(user_prompt, max_new_tokens=256, temperature=0.7, top_k=50, top_p=0.95):\n",
    "    \"\"\"\n",
    "    Generates a model's response based on the user prompt using completion API.\n",
    "\n",
    "    Args:\n",
    "        user_prompt (dict): Dictionary with \"role\" and \"content\" for the prompt.\n",
    "        max_new_tokens (int, optional): The maximum number of new tokens to generate. Defaults to 256.\n",
    "        temperature (float, optional): Sampling temperature, higher values make output more random. Defaults to 0.7.\n",
    "        top_k (int, optional): Number of highest probability tokens considered for sampling. Defaults to 50.\n",
    "        top_p (float, optional): Cumulative probability threshold for token selection. Defaults to 0.95.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated response from the model.\n",
    "    \"\"\"\n",
    "    role = user_prompt[\"role\"]\n",
    "    content = user_prompt[\"content\"]\n",
    "    prompt_full = f\"<|{role}|>{content}<|end|>\"\n",
    "    payload = {\"prompt\": prompt_full, \"max_tokens\": max_new_tokens, \"temperature\": temperature}\n",
    "    result = requests.post(request_post_completion, json=payload, stream=True)\n",
    "    result_str = json.loads(result.content)\n",
    "    model_output = result_str[\"text\"]\n",
    "    initial_response = model_output.split(\"<|end|>\")[0]\n",
    "    initial_response = initial_response.replace(\"<|assistant|> \", \"\")\n",
    "    return initial_response\n",
    "\n",
    "def get_summary(context):\n",
    "    \"\"\"\n",
    "    Generates a summary for the provided context using the model.\n",
    "\n",
    "    Args:\n",
    "        context (str): The context to summarize.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated summary.\n",
    "    \"\"\"\n",
    "    summary_prompt = \"Given the following text, generate a summary getting the most important points within 6 to 11 sentences.\\nText: \" + context\n",
    "    user_prompt = {\"role\": \"user\", \"content\": summary_prompt+\"\\nSummary:\"}\n",
    "    summary = generate_model_response(user_prompt, max_new_tokens=512, temperature=0.15)\n",
    "    summary = summary.replace(\"\\n\\n\", \"\\n\")\n",
    "    return summary\n",
    "\n",
    "def get_answered_question(question, summaries=None):\n",
    "    \"\"\"\n",
    "    Provides an answer to the given question, optionally using additional summaries.\n",
    "\n",
    "    Args:\n",
    "        question (str): The question to be answered.\n",
    "        summaries (dict, optional): Additional summaries to include in the context. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the answer, context, context page, and context UID.\n",
    "    \"\"\"\n",
    "    context, context_uid = get_search_results(question)\n",
    "    context_page = context_uid.split(\"_\")[0]\n",
    "    if summaries:\n",
    "        context = context + \"\\n\" + \"\\n\".join(summaries.values())\n",
    "    user_prompt = {\"role\": \"user\", \"content\": \"You are going to receive a description of a medical task from the user. It is going to be combined with a text of reference providing you with source of truth. Give suggestions basing you answer only on this text. Do not hallucinate! Write only the answer of the question without more information.\\nQuestion: \"+ question_txt +\"\\nText: \"+context+\"\\nSuggestions:\"}\n",
    "    answer = generate_model_response(user_prompt, max_new_tokens=512, temperature=0.15)\n",
    "    return answer, context, context_page, context_uid\n",
    "\n",
    "def get_followup_question(question, context_uid, df=df):\n",
    "    \"\"\"\n",
    "    Generates a follow-up question based on the given question and context UID.\n",
    "\n",
    "    Args:\n",
    "        question (str): The initial question.\n",
    "        context_uid (str): Context UID to find detailed context in the DataFrame.\n",
    "        df (pandas.DataFrame): DataFrame containing the context data.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the follow-up question and broad context.\n",
    "    \"\"\"\n",
    "    row_index = df[df[\"context_uid\"] == context_uid].index[0]\n",
    "    broad_context = \"\\n\".join(df.iloc[(row_index-1):(row_index+2)].context.values)\n",
    "    followup_prompt = \"Given the initial question and the text that you have received, generated a follow-up question to better understand the case. Ask questions only related to the task for clarification. Do not ask exam style question, but ask questions requiring contextual information from the user.\"\n",
    "    user_prompt = {\"role\": \"user\", \"content\":  followup_prompt+ \" Do not hallucinate! Write only the follow-up question without more information.\\nQuestion: \"+ question_txt +\"\\nText: \"+broad_context+\"\\nFollow-up question:\"}\n",
    "    followup_question = generate_model_response(user_prompt, max_new_tokens=128, temperature=0.15)\n",
    "    followup_question = followup_question.split(\"\\n\\n\")[0]\n",
    "    return followup_question, broad_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc68b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_situation = input(\"Describe what you need my help with.\\n\")\n",
    "visited_pages = {}\n",
    "passes = 0\n",
    "summaries = {}\n",
    "#a later version would have a protection, query splitter, domain checker etc here\n",
    "question_txt = initial_situation\n",
    "answer, context, context_page, context_uid = get_answered_question(question_txt)\n",
    "#TODO add the context chunk index too\n",
    "if visited_pages.get(context_page):\n",
    "    visited_pages[context_page]+=1\n",
    "else:\n",
    "    visited_pages[context_page]=1\n",
    "final_ouput = answer + \"\\nTaken from page: \" + str(context_page)\n",
    "print(\"Context: \" + context)\n",
    "print(\"============================\")\n",
    "print(\"Answer: \" + final_ouput)\n",
    "while True:\n",
    "    passes+=1\n",
    "    satisfactory_answer = True if input(\"Are you happy with the answer?\\n\")==\"Yes\" else False\n",
    "    if satisfactory_answer:\n",
    "        print(\"Pleasure to help!\")\n",
    "        print(\"The pages visited were the following:\")\n",
    "        for key, value in visited_pages.items():\n",
    "            print(\"Page number \"+ str(key) + \" was visited \" + str(value) + \" times\")\n",
    "        break\n",
    "    else:\n",
    "\n",
    "        row_index = df[df[\"context_uid\"]==context_uid].index[0]\n",
    "        followup, broad_context = get_followup_question(question_txt, context_uid)\n",
    "        print(\"Follow-up question: \"+followup)\n",
    "        user_answer = input(\"Your answer: \")\n",
    "        summaries[context_uid] = get_summary(broad_context)\n",
    "        question_txt = user_answer\n",
    "        answer, context, context_page, context_uid = get_answered_question(question_txt, summaries=summaries)\n",
    "\n",
    "        if visited_pages.get(context_page):\n",
    "            visited_pages[context_page]+=1\n",
    "        else:\n",
    "            visited_pages[context_page]=1\n",
    "        final_ouput = answer + \"\\nTaken from page: \" + str(context_page)\n",
    "        print(\"Context: \" + context)\n",
    "        print(\"============================\")\n",
    "        print(\"Answer: \" + final_ouput)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
